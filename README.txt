Так как репозиторий содержит подмодуль, слонировать его необходимо следующей командой:
git clone --recurse-submodules https://github.com/1numco/avito.git

Структура файлов: 
main.cpp - файл, который является выполненным тестовым заданием

helper.py - скрипт, который записывает в эталонные файлы (нужны для проверки работы функциональности)
правильный выход для определенного входного файла.

text_files - каталог с файлами для тестовым

include - каталог с заголовочными файлами

tests - каталог с cpp файлами для тестов

googletests - гугл тесты, в случае, если на машине, где будет запускаться тестовое, они не установлены

Если на вашей машине вдруг нет гуглтестов, то вот гайд по установке:
cd <TaskDirectory>/googletests
mkdir build
cd build
cmake ..
make install

После этого cmake сможет найти пакет гуглтестов в окружении

Для сборки моего проекта используется cmake, версии больше 3.0

Гайд по сборке:
cd <TaskDirectory>
mkdir build
cd build
cmake ..
make

После этого в билд директории появятся бинарники с говорящими названиям

main - бинарник с необходимой для задания функциональностью

остальное - тесты

Что тестируется:
Из текста задания я понял, что вам важна скорость работы алгоритма.
Поэтому изначально продумывал несколько вариантов реализации (итеративно от первого, 
что пришло на ум, до финального) и нужно было убедиться, что финальный алгоритм действительно 
быстрее всех на реальных данных.
Поэтому, чтобы унифицировать тестирование, сделать его более точным и тестировать только "кор-алгоритм",
был реализован пайплайн обработки файлов, где отдельные слова помещались в вектор и этот вектор 
подавался на вход кор-функции. Этот пайплайн может считать время работы кор-функции, а может просто запустить
себя без измерения времени. Измерение времени используется в перформанс тестах, простой запуск - во всех других.
Тесты запускаются для пайплайна с 3 разными кор-функциями и с FinalFunction - реализацией тестового
Тесты важны для проверки корректности поведения функций для разных входных данных.

Алгоритм из FinalFunction использует хэш-мапу для подсчета частот слов. Вставка и поиск по хэш-мапе 
происходи за амортизированную константу. Соотвественно это дает нам линейное время заполнения мапы словами из файла.
Дальше мапа передает свои данные в очередь с приоритетом, что по факту является heap, и, несмотря на то, 
что сложность вставки в хип логарифмическая, для построения хипа используется heapify, который строит 
кучу за линейное от количества элементов для построения время. Поэтому общая оценка сложности работы алгоритма - O(n).
Что довольно неплохо для такой задачи.

Спасибо за прикольное тестовое)
Хорошего вам дня, уважаемый ревьюер!
Надеюсь на скорую и содержательную обратную связь:)


После постановки задачи на повышение скорости работы функции я провел исследование ее производительности. Условно
разделил функцию на 3 части - обработка символов из файла для получения словаря слов, построение приоритетной очереди и 
запись в файл результатов. Соотношение времени работы этих частей оказалось примерно 5:1:2.
Построение приоритетной очереди - самая незатратная часть работы и самая оптимизированная и с алгоритмической точки зрения 
и с точки зрения языковой конструкции (одна строчка). Решил, что модифицировать эту часть как-то бессмысленно.
Теперь запись в файл. Несколько более оптимально сделал вывод в файл, но значительных улучшений это не принесло. Далее 
убрал вывод в файл, чтобы выяснить влияние операции работы с файлом в этой части. Оказалось, что просто достать все элементы
из очереди всего на 10% быстрее, чем достать и записать их в файл. Поэтому оптимизация на этом закончилась.
Осталась самая прожорливая часть - считывание из файла слов и формирование словаря. Главная идея оптимизации - избавиться
от использования затратных STL контейнеров и по максимуму использовать сишный подход. То, что раньше делали лябмды и контейнеры
скрытно от меня, теперь я делаю более явно и без ненужного оверхэда. Итог оптимизации этой части: удалось в 2.5-3 раза уменьшить
время работы.

Итого на моей машине, не предназначенной для перформанс тестирования, отношение времени работы FinalFunction к 
FinalFunctionUpgraded - 1.4-1.9 раз в зависимости от запуска. среднее - на уровне 1.6 раз



